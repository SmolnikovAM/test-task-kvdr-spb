# Задание в процессе переработки

## Тестовое задание. Тестовое задание для Node.js.

**Содержание:**

1. Постановка задачи
2. Пояснение решения
3. Установка
4. Запуск
5. История _code review_
   1. _Code review №1_
   2. Примечения по исправлению ошибок
6. TODO

#### 1. Постановка задачи.

Реализовать http-server на базе фреймворка Koa2, соответствующий следующим требованиям:

1. Работает с базой данных mysql. В субд есть таблица books(1e5 записей, заполнена случайными данными). У каждой книги должны быть поля _title, date, author, description, image_. Реализация смежных таблиц на усмотрение кандидата, архитектурные решения оцениваются.​ **Работает на "чистом" SQL**
2. Присутствуют три контроллера:

   1. Добавляет записи в субд
   2. Отдает. Сделать возможность сортировки|группировки по всем возможным полям, возможность порционного получения с оффсетом **\***
   3. Изменяет

**\*** - приветствуются варианты кэширования

### 2. Пояснение решения.

**Разбор условия**
Должна присутствовать как минимум таблица books. Но в следующем предложении уже говорится о бизнес-сущности "книги", что не подразумевает, что все эти поля должны быть в одной таблице.

Автор может написать несколько книг, книга может иметь несколько авторов. C точки зрения реляционных БД это соотношение "многие ко многим". Обычно это три таблицы. Одна для авторов, вторая для книг, а третья их связывает.

В явном виде присутствует указание, что реализация должна быть на "чистом" SQL. Это подразумевает, что использоваение библиотек ORM, QueryBuilder запрещено. То есть нужно использовать обычный дравйвер для nodejs. Учитывая, что упор в задании идет на понимание SQL, то постараемся максимальный функционал по работе с данными перенести на базу данных.

Пункты про добавление и изменение данных вполне понятны, а с получением необходимо детально разобраться.

_"Сделать возможность сортировки|группировки"_**\*\***. Двоякого толкования сортироки быть не должно, а вот с группировкой вполне может. Ее можно трактовать с позиции SQL или структурирования данных.

_группировка SQL_ в отрыве от агрегатных функций бесполезна (можно заменить на distinct)

А группировка данных в понимании разделения на отдельные сущности/множества выглядит логичнее. При том, что данные у нас могут подразумевать вложенность. А если учесть, что мы строим API, то это вполне логичные данные, которые могут требоваться для frontend.

К примеру

```js
{
    author:{
        name: 'Name',
        books: [
            {title: 'book1'},
            {title: 'book2'}
        ]
    }
}
```

_Возможность порционного получения с оффсетом_ Сначала кажется, что это простое добавление в запрос limit и offset. Достаточно рассмотреть следющий запрос. К примеру, мы хотим сгруппировать книги по авторам и получть первые 10 значений. В данном запросе нас интересует, что бы у авторов были все книги, которые им принадлежат. Но SQL-запрос - это простая таблица, а значит простым добаление limit 10, мы выберем только первые 10 книг, а только потом сможем сделать группировку по совпадающим значениям. В итоге у нас получится в лучшем случае 10 авторов, но явно не все книги авторов.

Кэширование является сложной задачей, в идеале ее решение должено быть построено на основе статистики уже работающего сервиса, либо основана на каких-то предположениях о доменной области. В противном случае можно решать несуществующую задачу. В данной задаче сделаем предположение, что одинаковые запросы получения могут потребоваться чаще одного раза за определенное время, поэтому их нужно где-то сохранять. Нужно учитывать, что мы не можем гарантировать, что изменение данных не затронет какую-то информацию. Построение данной модели становится чрезвычайно сложной задачей для тестового задания. Поэтому любой запрос, который модифицирует данные полностью сбрасывает кеш.

**\*\*** - можно трактовать "|" как знак или, но будет считать, что требуется обе функциональности
**Данные.**

**Структура БД.**

```
table: authors
    id     <---------┐  primary key
    name             |
                     |
table: book_authors  |
    author_id  ------┘  compound primary key
    book_id    ------┐
                     |
table: books         |
    id       <-------┘  primary key
    title
    date
    description
    image               path_to_file
```

Для предотвращения возможных дубликатов связки автор-книга используем _compound primary key_ `(author_id, book_id)`

**Взаимодействие с данными.**

На уровне постановки задания оговорено условие, что сервер должен работать с "чистым" SQL.
Из этого следует, что запрещено использовать библиотеки, которые в автоматическом режиме конструируют sql-запросы, можно только использовать библиотеку-драйвер к mysql

Есть несколько вариантов решения данной задачи:

<table>
    <thead>
        <tr>
            <th>Вариант</th>
            <th>Плюсы</th>
            <th>Минусы</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td rowspan=3>Конкатенация строк</td>
            <td rowspan=3>Простая начальная реализация</td>
            <td>Хрупкость тестов</td>
        </tr>
        <tr>
            <td>Внесение изменений в доменную область требует внесения изменений почти по всей кодовой базе</td>
        </tr>
        <tr>
            <td>Смешивание бизнес-логики и транспортного уровня</td>
        </tr>
        <tr>
            <td rowspan=2>Создание конструктора запросов</td>
            <td>Гибкость при разработке</td>             
            <td>Сложность языка SQL</td>            
        </tr>
        <tr>        
            <td>Изолируемость различных модулей программы</td>            
            <td>Дополнительные затраты на написание unit-тестов</td>
        </tr>       
        <tr>         
        </tr>        
    </tbody>
</table>

Следовательно в решении будет:

1. Создан примитивный QueryBuilder, удовлетворяющий решению текущей здачи, но с возоможностью расширения.
2. На основе него построена абстракция для работы с данными.

**Реализиция QueryBuilder и ее ограничения**

Язык SQL запросов является сложным, но стоит отметить, что для удовлетвория целей исходного задания реализация полноценного функционала конструктора запросов SQL не требуется.

Определим минимальный набор функциональности, которой должен обладать конструктор:

1. Добавление данных в таблицу. При этом должна поддерживаться конструкции вида `insert into <table> (<user fields>) values (<user values>)(...)(...)`.
2. Обновление данных `upate <table> set <fields = value> where id = <user data_id>`
3. Удаление данных `delete from <table> where id = <user data_id>`
4. Выборка данных

```sql
select
  <user fields>
from <tables and joins>
where <user conditions>
group by <user goup by>
order by <user order by>
limit <user-limit> offset <user-offser>
```

При разборе задачи упоминался случай, когда требуется групировка данных совместно с оффсетом. Значит может потребоваться конструкция вложенных запросов.

```sql
select
t2.*
from
(select name from authors group by name where <conditions>
limit <limit> offset <offset> ) t1
left join
(select * from authors group by name where <conditions>) t2
where t1.name = t2.name
```

**API конструктора запросов**

За основу QueryBuilder не брались текущие решения, а строилась отдельная модель.

Определим сущности
Table - таблица

Field - поля таблицы

Query - запрос

Join - техническая сущность, которую пользователь не создает, но она необходима для построения запросов.

Приведем несколько примеров работы API.

```js
const table = new Table('table');
const query = new QueryBuilder();
const sql = query
  .select() // автоматически подставит *
  .from(table)
  .toString(); //  select * from `table`;
```

выборка из двух таблиц

```js
const ta = new Table('tableA');
const tb = new Table('tableB');
const query = new QueryBuilder();
const fieldsList = [ta.field('field1').as('new_name'), tb.field('field2')];
const join = ta.leftJoin(tb).on([ta.field('id'), tb.field('table1_id')]);

const sql = query
  .select(fieldsList)
  .from(join)
  .toString();
```

что будет эквивалентно следующему sql-запросу. Алиас создается автоматически самим конструктором.

```sql
select
 `alias1`.`field1` as `new_name`
,`alias2`.`field2` as `field2`
from `tableA` `alias1`
    left join `tableB` `alias2` on
    (`alias1`.`id` = `alias2`.`table1_id`)
```

Таблица может быть создана из запроса и потом испольльзована в дальнейшей

```js
const query = new QueryBuilder();
...
const subQuery = new Table(query);
```

Вызов происходит методом execute. Функция взаимодействия с БД передается при создании запроса
Параметры введенные пользователем экранируются

```js
const table = new Table('test');
const query = new QueryBuilder(dbQuery);
await query
  .update(table)
  .set([[table.field('field'), 'new value']])
  .where([[table.field('field'), 'old value']])
  .execute();
```

запрос будет выглядеть следующим образом

```sql
update 'test'
  set 'test'.'field' = ?
where 'test'.'field' = ?
```

Более подробно работу QueryBuilder можно посмотреть в файле _queryBuilder.unit.js_

Теоретически можно данный конструктор расширять.

_Основной вывод_
Создана интересная, но многословная реализация QueryBuilder

**Обложка книги.**

Поле image хранит путь к файлу.

**Арихитектура и структура файлов**

Сделаем более сложный вариани, что все все поля, с которыми будет взаимодействовать front будут называться как указано в задании, а в бекенде буде происходить маппинг

У нас не должно быть дублирования имен авторов. Можно сделать это на уровне приложения, но можно и на уровне базы данных;

Пусть все e2e тесты проходить параллельно. Для этого есть несколько вариантов:
поднимать контейнеры в Docker
...

В приложения будут созданы неходимые сущности и прокидываться в через контекс.

К примеру все роуты должны быть созданы отдельно от функии createApp. Так как функция Router.prototype.use вносит изменения в переданный ему роутер. (Примет такого поведения можно посмотреть тут)

В тестах имя базы данных создадим на основе uuid4. Для того, что бы базы удалялись автоматически будем использовать метод afterAll и удалять из Set

**Структура приложения**

Роутинги создаются и только потом подключаются

app.context.repository - передается созданная копия репозитория

**Кэширование.**

Стратегия кэширования основана на поиске сделанного ранее SQL запроса. Время жизни кэша определяется в переменной окружения, default: 1 час. Любая операция мутации данных сбрасывает кэш.

**Тестирование.**

```
grant insert, select, update, delete on test.* to testuser@localhost;
flush privileges
```

```
grant create, drop, grant option, reload, insert, select, update, delete on *.* to 'superuser'@'localhost';
```

Для тестирования был выбран jest и supertest. Unit тесты нужны для сервисов и QueryBuilder.

Можно протестировать chache сервис путем отключения база данных во время тестирования.

### 3. Установка.

```
npm install
```

требуется бд mysql и пользователь с правами на [create, drop, insert, update, select, delete] table;
передача параметров реализована через переменные окружения

### 4. Запуск.

Пример запуска e2e - тестирования.

```
export KVDRTEST_db__host=localhost &&
export KVDRTEST_db__database=kvadrotest &&
export KVDRTEST_db__user=testuser &&
export KVDRTEST_db__password=password &&
export KVDRTEST_staticFolder="./staticTest" &&
npm run test:e2e
```

Для "рабочей" базы необходим другой путь

```
KVDRTEST_db__host=localhost &&
KVDRTEST_db__database=kvadro &&
KVDRTEST_db__user=testuser &&
KVDRTEST_db__password=password &&
npm start
```

Загрузка фикстур

```
KVDRTEST_db__host=localhost &&
KVDRTEST_db__database=kvadro &&
KVDRTEST_db__user=testuser &&
KVDRTEST_db__password=password &&
npm run seed
```

Для unit-тестов база не требуется

```
npm run test:unit
```

### 5. История _code review_.

#### 5.1. _Code review №1_.

Пояснение:
Версия [репзитория](https://github.com/SmolnikovAM/test-task-kvdr-spb/tree/4e0558ceacb99450ad162198ee32884d5cf67820), на основе которого проходитло **code review**
каждое замечание имеет степень критичности по трехбальной шкале.

1. "Авторы и книги" - это классический вопрос собеседований. Тут зависимость "много ко многим". **3/3**
2. Полезно проверять опечатки. **0.5/3**
3. Не давать пользователем на create/drop **1/3**
4. В модуле rc есть возможность создавать специальные файлы для загрузки начальных параметров. Пользователю будет их проще поправить в файле. **0.5/3**
5. Рекомендация придерживаться классической структуры запуска тестов npm test. **0.5/3**
6. Боевую лучше используя написать NODE_ENV = "production". **1/3**
7. Ненужные параметры окружения env = "SEED"
8. Вместо runInBand можно было бы сделать запуск нескольких сущностей jest с несколькими БД
9. Не используемая зависимость **1/3**
10. Есть роут, который нежен только для теста. По хорошему у приложения не должно быть не нужных роутов. Можно было бы это обойти роутом helthcheck, который может быть использован kubernates **1/3**
11. У supertest есть fluent syntax, благодаря которому можно через chain делать expect. И Нужно было бы возвразать promise с результатами выполнения теста **1/3**
12. Тест с добавлением в таблицу авторов является хрупким, потому что проверка завязана на id. При распределенных серверах (один пишет только четные номера, а второй только нечетные) могут тесты проваливаться. Пожтому некорректно проверять id, потому что зависит от конкретной кофигурации sql-сервера **1/3**
13. Тест с insert author не достаточно проверяет поведение и мы не проверили, что сущность не добавилась в БД. Нужно было бы сделать еще один запрос на проверку списка и чтобы убедится, что эта сущность добавилась в БД. **3/3**
14. e2e тесты должны тестировать системы по принципу черного ящика. Поэтому проверять систему нужно только ее же внешними запросами, то есть не используя внутренние инструменты. **3/3**
15. не установлены pre commit hook для eslint
16. В синтаксисе mysql таблицы используются в кавычках **3/3**
17. Вместо send лучше назвать execute **1/3**
18. Присутствует закомментированный код. **1/3**
19. Куча файлов index.js. Это затрудняет навигацию. **0.5/3**
20. Нет обобщенного класса для работы с сущностями репозитория. **3/3**
21. Константы табличек лучше импортить снаружи, к примеру, из репозитория **0/3**
22. Лучше на каждый роут сделать отдельный файл и с ним схема так как они логически связаны. **3/3**
23. Ошибка при реализации кеша. То есть он должен только кешировать запрос, а согласно реализации он дополнительно делает запрос. **3/3**
24. _put_ вместо _patch_. **3/3**
25. Параметр большой картинки должен быть настраиваемым. **3/3**
26. У нормальных людей картинки грузятся через форму. Нужно отправлять форм-data **3/3**
27. middleware по cache должна быть экспортирована из cache service **3/3**
28. Запуск приложения привязан к переменным окружения. if(!module.parent) **2/3**

#### 5.2. Примечения по исправлению ошибок.

### 6. TODO

1. Тесты на cache - функциональность.
2. Полное покрытие тестами QueryBuilder
3. Полная проверка входяшийх параметров через ajv
